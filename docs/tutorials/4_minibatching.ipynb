{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Load from parent directory if not installed\n",
    "import importlib\n",
    "import os\n",
    "\n",
    "if not importlib.util.find_spec(\"sammo\"):\n",
    "    import sys\n",
    "\n",
    "    sys.path.append(\"../\")\n",
    "os.environ[\"CACHE_FILE\"] = \"cache/working_with_prompts.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Minibatching for Call Efficiency\n",
    "\n",
    "When annotating data, it is quite wasteful to use one LLM request per example, especially when the instructions are shared. \n",
    "\n",
    "Instead, we can use minibatching to improve *call efficiency*. Let's repeat the setup from the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# %load -r 3:25 _init.py\n",
    "import pathlib\n",
    "import sammo\n",
    "from sammo.runners import OpenAIChat\n",
    "from sammo.base import Template, EvaluationScore\n",
    "from sammo.components import Output, GenerateText, ForEach, Union\n",
    "from sammo.extractors import ExtractRegex\n",
    "from sammo.data import DataTable\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "\n",
    "if not \"OPENAI_API_KEY\" in os.environ:\n",
    "    raise ValueError(\"Please set the environment variable OPENAI_API_KEY'.\")\n",
    "\n",
    "_ = sammo.setup_logger(\"WARNING\")  # we're only interested in warnings for now\n",
    "\n",
    "runner = OpenAIChat(\n",
    "    model_id=\"gpt-3.5-turbo-16k\",\n",
    "    api_config={\"api_key\": os.getenv(\"OPENAI_API_KEY\")},\n",
    "    cache=os.getenv(\"CACHE_FILE\", \"cache.tsv\"),\n",
    "    timeout=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# %load -s load_data,accuracy _init.py\n",
    "def load_data(\n",
    "    url=\"https://github.com/google/BIG-bench/raw/main/bigbench/benchmark_tasks/implicatures/task.json\",\n",
    "):\n",
    "    task = json.loads(requests.get(url).content)\n",
    "    # convert label to single string\n",
    "    for x in task[\"examples\"]:\n",
    "        x[\"output\"] = max(x[\"target_scores\"], key=x[\"target_scores\"].get)\n",
    "\n",
    "    return DataTable.from_records(\n",
    "        task[\"examples\"],\n",
    "        input_fields=\"input\",\n",
    "        constants={\"instructions\": task[\"task_prefix\"]},\n",
    "    )\n",
    "\n",
    "def accuracy(y_true: DataTable, y_pred: DataTable) -> EvaluationScore:\n",
    "    y_true = y_true.outputs.values\n",
    "    y_pred = y_pred.outputs.values\n",
    "    n_correct = sum([y_p == y_t for y_p, y_t in zip(y_pred, y_true)])\n",
    "\n",
    "    return EvaluationScore(n_correct / len(y_true))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Manual Minibatching\n",
    "To appreciate the convinience of `DataFormatters`, we start by doing within-prompt minibatching ourselves.\n",
    "Using the [handlebars syntax](https://handlebarsjs.com/guide/), we loop over all input rows in a minibatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labeling_prompt = GenerateText(\n",
    "    Template(\n",
    "        \"Instructions:{{constants.instructions}}\\nOutput labels: yes, no\\n\"\n",
    "        \"{{#each inputs}}Input: {{this}}{{/each}}\\nOutput:\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The only other changes we need to make is to specify the minibatch size in the Output component and also make sure the output gets split into lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minibatches[##################################################################################]1/1[00:00<00:00, 62.50it/s]\n",
      "\n",
      "Exception: Minibatch results do not have right length (need: 10, got: 1)\n"
     ]
    }
   ],
   "source": [
    "labeling_outputter = Output(labeling_prompt, minibatch_size=10)\n",
    "mydata = load_data()\n",
    "sample = mydata.sample(10, seed=42)\n",
    "\n",
    "try:\n",
    "    result = labeling_outputter.run(runner, sample)\n",
    "except Exception as e:\n",
    "    print(f\"\\nException: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Oh, no - there is something wrong with the minibatch results. The number of answers we get from a single LLM call need to be aligned with all the input rows which is where we fail.\n",
    "\n",
    "Going back to the prompt, we realize that we forgot to extract all valid answers from the `GenerateText` call! Let's fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minibatches[###################################################################################]1/1[00:00<??:??, 0.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "+--------------------------------------------------------------+----------+\n",
       "| input                                                        | output   |\n",
       "+==============================================================+==========+\n",
       "| Speaker 1: 'You do this often?' Speaker 2: 'It's my first    | yes      |\n",
       "| time.'                                                       |          |\n",
       "+--------------------------------------------------------------+----------+\n",
       "| Speaker 1: 'Are you trying to make me mad?' Speaker 2: 'I'm  | no       |\n",
       "| just saying, I'd understand if you were upset. '             |          |\n",
       "+--------------------------------------------------------------+----------+\n",
       "| Speaker 1: 'You want answers?!' Speaker 2: 'I want the       | no       |\n",
       "| truth.'                                                      |          |\n",
       "+--------------------------------------------------------------+----------+\n",
       "| Speaker 1: 'Are you able to carry the box?' Speaker 2: 'It   | yes      |\n",
       "| is as light as a feather.'                                   |          |\n",
       "+--------------------------------------------------------------+----------+\n",
       "| Speaker 1: 'Is it hot outside?' Speaker 2: 'You could fry an | no       |\n",
       "| egg on the sidewalk.'                                        |          |\n",
       "+--------------------------------------------------------------+----------+\n",
       "| Speaker 1: 'Should we repay you?' Speaker 2: 'There is no    | no       |\n",
       "| charge for awesomeness, or attractiveness.'                  |          |\n",
       "+--------------------------------------------------------------+----------+\n",
       "| Speaker 1: 'I wonder, Bob, if you can handle my car?'        | no       |\n",
       "| Speaker 2: 'It's an ordinary six cylinder.'                  |          |\n",
       "+--------------------------------------------------------------+----------+\n",
       "| Speaker 1: 'Did you order the code red?' Speaker 2: 'You're  | yes      |\n",
       "| goddamn right.'                                              |          |\n",
       "+--------------------------------------------------------------+----------+\n",
       "| Speaker 1: 'You've seen rain before... right?' Speaker 2:    | no       |\n",
       "| 'We don't get out much.'                                     |          |\n",
       "+--------------------------------------------------------------+----------+\n",
       "| Speaker 1: 'Does anyone know how to pick a lock?' Speaker 2: | yes      |\n",
       "| 'Sure. Picking locks is my thing.'                           |          |\n",
       "+--------------------------------------------------------------+----------+\n",
       "Constants: {'instructions': \"Does Speaker 2's answer mean yes or no? \"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeling_outputter = Output(\n",
    "    ExtractRegex(labeling_prompt, \"(?i)yes|no\"), minibatch_size=10\n",
    ")\n",
    "result = labeling_outputter.run(runner, sample)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Nice! With a single LLM call, we now annotated 10 examples! It was, however, a bit annoying to have to manually format the minibatches. Luckily, `SAMMO` provides a `MetaTemplate` class for common data annotation tasks that simplifies the set-up considerably.\n",
    "\n",
    "## Using the `MetaPrompt` class\n",
    "\n",
    "The `MetaPrompt` class takes a nested list of instructions, an argument specifying how instructions are rendered and a `DataFormatter` instance that is shared for in-context examples and input examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sammo.instructions import MetaPrompt, Section, Paragraph, InputData, FewshotExamples\n",
    "from sammo.dataformatters import (\n",
    "    QuestionAnswerFormatter,\n",
    "    JSONDataFormatter\n",
    ")\n",
    "\n",
    "mprompt = MetaPrompt(\n",
    "    [\n",
    "        Section(\"Instructions\", mydata.constants[\"instructions\"]),\n",
    "        Section(\"Examples\", FewshotExamples(mydata.sample(3, seed=43))),\n",
    "        Paragraph(\"\\nOutput labels: yes, no\"),\n",
    "        Paragraph(InputData()),\n",
    "    ],\n",
    "    render_as=\"markdown\",\n",
    "    data_formatter=QuestionAnswerFormatter([\"yes\", \"no\"]),\n",
    ").with_extractor(\"empty_result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We have now structured our labeling task into a section and a few paragraphs. The `DataFormatter` class does all the data formatting for us, and calling `with_extractor()` wraps the response with the right extractor class to match our data formatter. We have also added a section with fewshot (incontext) examples to show the model how the output format looks.\n",
    "\n",
    "We can just look at the current metaprompt to see what was generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtractRegex(\n",
      "  child = GenerateText(\n",
      "    child = MetaPrompt(\n",
      "      structure = [\n",
      "        0 : Section(\n",
      "          name = 'Instructions',\n",
      "          content = 'Does Speaker 2's answer mean yes or no? ',\n",
      "          id = None\n",
      "        ),\n",
      "        1 : Section(\n",
      "          name = 'Examples',\n",
      "          content = FewshotExamples(\n",
      "            data = +--------------------------------------------------------------+----------+\n",
      "| input                                                        | output   |\n",
      "+==============================================================+==========+\n",
      "| Speaker 1: 'Should I bring my umbrella?' Speaker 2: 'Better  | yes      |\n",
      "| safe than sorry.'                                            |          |\n",
      "+--------------------------------------------------------------+----------+\n",
      "| Speaker 1: 'Do you have a girl worth fighting for?' Speaker  | no       |\n",
      "| 2: 'Wish that I had.'                                        |          |\n",
      "+--------------------------------------------------------------+----------+\n",
      "| Speaker 1: 'Do you think I should attend the interview?'     | yes      |\n",
      "| Speaker 2: 'Do you want to be a failure for the rest of your |          |\n",
      "| life?'                                                       |          |\n",
      "+--------------------------------------------------------------+----------+\n",
      "Constants: {'instructions': \"Does Speaker 2's answer mean yes or no? \"},\n",
      "            n_examples = None,\n",
      "            name = None\n",
      "          ),\n",
      "          id = None\n",
      "        ),\n",
      "        2 : Paragraph(\n",
      "          content = '\n",
      "Output labels: yes, no',\n",
      "          id = None\n",
      "        ),\n",
      "        3 : Paragraph(\n",
      "          content = InputData(\n",
      "            id_offset = 0,\n",
      "            name = None\n",
      "          ),\n",
      "          id = None\n",
      "        )\n",
      "      ],\n",
      "      render_as = 'markdown',\n",
      "      data_formatter = QuestionAnswerFormatter(\n",
      "        all_labels = [\n",
      "          0 : 'yes',\n",
      "          1 : 'no'\n",
      "        ]\n",
      "      ),\n",
      "      name = None,\n",
      "      seed = 0\n",
      "    ),\n",
      "    name = None,\n",
      "    system_prompt = None,\n",
      "    history = None,\n",
      "    seed = 0,\n",
      "    randomness = 0,\n",
      "    max_tokens = None,\n",
      "    on_error = 'raise'\n",
      "  ),\n",
      "  regex = '^A[^:]*:\\s*([^\\n]*)',\n",
      "  max_matches = None,\n",
      "  strip_whitespaces = True\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(mprompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We can see that the output from `GenerateText` gets parsed by `ExtractRegex`. Let's run it on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minibatches[#################################################################################]2/2[00:00<00:00, 125.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "+--------------------------------------------------------------+----------+\n",
       "| input                                                        | output   |\n",
       "+==============================================================+==========+\n",
       "| Speaker 1: 'You do this often?' Speaker 2: 'It's my first    | no       |\n",
       "| time.'                                                       |          |\n",
       "+--------------------------------------------------------------+----------+\n",
       "| Speaker 1: 'Are you trying to make me mad?' Speaker 2: 'I'm  | no       |\n",
       "| just saying, I'd understand if you were upset. '             |          |\n",
       "+--------------------------------------------------------------+----------+\n",
       "| Speaker 1: 'You want answers?!' Speaker 2: 'I want the       | yes      |\n",
       "| truth.'                                                      |          |\n",
       "+--------------------------------------------------------------+----------+\n",
       "| Speaker 1: 'Are you able to carry the box?' Speaker 2: 'It   | yes      |\n",
       "| is as light as a feather.'                                   |          |\n",
       "+--------------------------------------------------------------+----------+\n",
       "| Speaker 1: 'Is it hot outside?' Speaker 2: 'You could fry an | yes      |\n",
       "| egg on the sidewalk.'                                        |          |\n",
       "+--------------------------------------------------------------+----------+\n",
       "Constants: {'instructions': \"Does Speaker 2's answer mean yes or no? \"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = Output(mprompt, minibatch_size=5, on_error=\"empty_result\").run(\n",
    "    runner, sample\n",
    ")\n",
    "result[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let's also look at what an actual prompt looked like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Instructions\n",
      "Does Speaker 2's answer mean yes or no? \n",
      "\n",
      "# Examples\n",
      "Q[0]: Speaker 1: 'Should I bring my umbrella?' Speaker 2: 'Better safe than sorry.'\n",
      "A[0]: yes\n",
      "\n",
      "Q[1]: Speaker 1: 'Do you have a girl worth fighting for?' Speaker 2: 'Wish that I had.'\n",
      "A[1]: no\n",
      "\n",
      "Q[2]: Speaker 1: 'Do you think I should attend the interview?' Speaker 2: 'Do you want to be a failure for the rest of your life?'\n",
      "A[2]: yes\n",
      "\n",
      "\n",
      "\n",
      "Output labels: yes, no\n",
      "\n",
      "\n",
      "Q[0]: Speaker 1: 'You do this often?' Speaker 2: 'It's my first time.'\n",
      "\n",
      "Q[1]: Speaker 1: 'Are you trying to make me mad?' Speaker 2: 'I'm just saying, I'd understand if you were upset. '\n",
      "\n",
      "Q[2]: Speaker 1: 'You want answers?!' Speaker 2: 'I want the truth.'\n",
      "\n",
      "Q[3]: Speaker 1: 'Are you able to carry the box?' Speaker 2: 'It is as light as a feather.'\n",
      "\n",
      "Q[4]: Speaker 1: 'Is it hot outside?' Speaker 2: 'You could fry an egg on the sidewalk.'\n"
     ]
    }
   ],
   "source": [
    "print(result.outputs.llm_requests[0][0][0][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Changing the data format\n",
    "\n",
    "How about using JSON instead of this line-by-line format?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "modified_mprompt = MetaPrompt(\n",
    "    [\n",
    "        Section(\"Instructions\", mydata.constants[\"instructions\"]),\n",
    "        Section(\"Examples\", FewshotExamples(mydata.sample(3, seed=43))),\n",
    "        Paragraph(\"\\nOutput labels: yes, no\"),\n",
    "        Paragraph(InputData()),\n",
    "    ],\n",
    "    render_as=\"markdown\",\n",
    "    data_formatter=JSONDataFormatter(),  # <-- changed\n",
    ").with_extractor(\"empty_result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "VoilÃ ! Let's run it on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minibatches[###################################################################################]2/2[00:00<??:??, 0.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "+--------------------------------------------------------------+----------+\n",
       "| input                                                        | output   |\n",
       "+==============================================================+==========+\n",
       "| Speaker 1: 'You do this often?' Speaker 2: 'It's my first    | no       |\n",
       "| time.'                                                       |          |\n",
       "+--------------------------------------------------------------+----------+\n",
       "| Speaker 1: 'Are you trying to make me mad?' Speaker 2: 'I'm  | no       |\n",
       "| just saying, I'd understand if you were upset. '             |          |\n",
       "+--------------------------------------------------------------+----------+\n",
       "| Speaker 1: 'You want answers?!' Speaker 2: 'I want the       | no       |\n",
       "| truth.'                                                      |          |\n",
       "+--------------------------------------------------------------+----------+\n",
       "| Speaker 1: 'Are you able to carry the box?' Speaker 2: 'It   | no       |\n",
       "| is as light as a feather.'                                   |          |\n",
       "+--------------------------------------------------------------+----------+\n",
       "| Speaker 1: 'Is it hot outside?' Speaker 2: 'You could fry an | no       |\n",
       "| egg on the sidewalk.'                                        |          |\n",
       "+--------------------------------------------------------------+----------+\n",
       "Constants: {'instructions': \"Does Speaker 2's answer mean yes or no? \"}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = Output(\n",
    "    modified_mprompt, minibatch_size=5, on_error=\"empty_result\"\n",
    ").run(runner, sample)\n",
    "result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Instructions\n",
      "Does Speaker 2's answer mean yes or no? \n",
      "\n",
      "# Examples\n",
      "[{\"id\": 0, \"input\": \"Speaker 1: 'Should I bring my umbrella?' Speaker 2: 'Better safe than sorry.'\", \"output\": \"yes\"}, {\"id\": 1, \"input\": \"Speaker 1: 'Do you have a girl worth fighting for?' Speaker 2: 'Wish that I had.'\", \"output\": \"no\"}, {\"id\": 2, \"input\": \"Speaker 1: 'Do you think I should attend the interview?' Speaker 2: 'Do you want to be a failure for the rest of your life?'\", \"output\": \"yes\"}]\n",
      "\n",
      "\n",
      "Output labels: yes, no\n",
      "\n",
      "\n",
      "[{\"id\": 0, \"input\": \"Speaker 1: 'You do this often?' Speaker 2: 'It's my first time.'\"}, {\"id\": 1, \"input\": \"Speaker 1: 'Are you trying to make me mad?' Speaker 2: 'I'm just saying, I'd understand if you were upset. '\"}, {\"id\": 2, \"input\": \"Speaker 1: 'You want answers?!' Speaker 2: 'I want the truth.'\"}, {\"id\": 3, \"input\": \"Speaker 1: 'Are you able to carry the box?' Speaker 2: 'It is as light as a feather.'\"}, {\"id\": 4, \"input\": \"Speaker 1: 'Is it hot outside?' Speaker 2: 'You could fry an egg on the sidewalk.'\"}]\n"
     ]
    }
   ],
   "source": [
    "print(result.outputs.llm_requests[0][0][0][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This is the convinience of using the `MetaPrompt` class! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
