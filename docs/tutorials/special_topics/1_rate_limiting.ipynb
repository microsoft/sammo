{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61643fe1-aa70-4f99-a3c4-a4d0577b70f3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "## Load from parent directory if not installed\n",
    "import importlib\n",
    "\n",
    "if not importlib.util.find_spec(\"sammo\"):\n",
    "    import sys\n",
    "\n",
    "    sys.path.append(\"../../\")\n",
    "\n",
    "CACHE_FILE = \"cache/special_topics.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65550492-591f-44f3-85a1-9bee6db2316e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# %load -r :19 ../_init.py\n",
    "import pathlib\n",
    "import sammo\n",
    "from sammo.runners import OpenAIChat\n",
    "from sammo.base import Template, EvaluationScore\n",
    "from sammo.components import Output, GenerateText, ForEach, Union\n",
    "from sammo.extractors import ExtractRegex\n",
    "from sammo.data import DataTable\n",
    "import json\n",
    "import requests\n",
    "\n",
    "API_CONFIG_FILE = pathlib.Path().cwd().parent.parent / \"config\" / \"personal.openai\"\n",
    "API_CONFIG = \"\"\n",
    "if API_CONFIG_FILE.exists():\n",
    "    API_CONFIG = API_CONFIG_FILE\n",
    "if not API_CONFIG:\n",
    "    raise ValueError('Please set API_CONFIG to {\"api_key\": \"YOUR_KEY\"}')\n",
    "\n",
    "_ = sammo.setup_logger(\"WARNING\")  # we're only interested in warnings for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dcda8e-55b7-4b73-a81a-90397af50b8b",
   "metadata": {},
   "source": [
    "# Rate Limiting\n",
    "\n",
    "Many APIs have rate limits, often in terms of number of requests within a certain time period or a total cost.\n",
    "\n",
    "You have three options to specify rate limits in {class}`~sammo.runners.Runner` (in increasing order of flexibility):\n",
    "\n",
    "1. Specify a number for the ``rate_limit`` parameter. This will enforce a requests per second limit equal to that number.\n",
    "2. Specify a list of {class}``~sammo.throttler.AtMost`` objects that are applied in an logical AND\n",
    "   fashion.\n",
    "3. Pass an instance of {class}`~sammo.throttler.Throttler` (or a subclass of it). This allows you to fine-tune some settings, e.g., how costs are calculated.\n",
    "\n",
    "## Simple rate limit (qps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8752663a-a4c2-4321-8655-75353dfe72d4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minibatches[###################################################################################]5/5[00:04<00:00, 1.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "+---------+----------+\n",
       "| input   | output   |\n",
       "+=========+==========+\n",
       "| 1       | I        |\n",
       "+---------+----------+\n",
       "| 2       | II       |\n",
       "+---------+----------+\n",
       "| 3       | III      |\n",
       "+---------+----------+\n",
       "| 4       | IV       |\n",
       "+---------+----------+\n",
       "| 5       | V        |\n",
       "+---------+----------+\n",
       "Constants: None"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner = OpenAIChat(model_id=\"gpt-3.5-turbo-16k\", api_config=API_CONFIG, rate_limit=1)\n",
    "Output(GenerateText(Template(\"Output as a latin numeral: {{input}}\"))).run(\n",
    "    runner, list(range(1,6))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb99566f-0e56-4110-b63b-e61983ffefa7",
   "metadata": {},
   "source": [
    "As specified, `SAMMO` issued exactly one prompt request per second."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64614da-c49e-44ae-84a2-5b824957fe13",
   "metadata": {},
   "source": [
    "## Advanced rate limits\n",
    "\n",
    "Let's say we want to make sure we never have more than 1 running request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16613f90-ce2b-4545-975d-6ac7133facae",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minibatches[###################################################################################]5/5[00:02<00:00, 1.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "+---------+----------+\n",
       "| input   | output   |\n",
       "+=========+==========+\n",
       "| 1       | I        |\n",
       "+---------+----------+\n",
       "| 2       | II       |\n",
       "+---------+----------+\n",
       "| 3       | III      |\n",
       "+---------+----------+\n",
       "| 4       | IV       |\n",
       "+---------+----------+\n",
       "| 5       | V        |\n",
       "+---------+----------+\n",
       "Constants: None"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sammo.throttler import AtMost\n",
    "\n",
    "runner = OpenAIChat(model_id=\"gpt-3.5-turbo-16k\", api_config=API_CONFIG, rate_limit=AtMost(1, \"running\"))\n",
    "\n",
    "Output(GenerateText(Template(\"Output as a latin numeral: {{input}}\"))).run(\n",
    "    runner, list(range(1,6))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20316f8-8588-4c9b-aace-b063bf6fcd1f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Or, you want to run five queries every 10 seconds, but make sure they have at least 100ms breaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f7d7dc3-cb56-4a61-8e18-4c129f2d46fb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minibatches[###################################################################################]5/5[00:00<00:00, 5.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "+---------+----------+\n",
       "| input   | output   |\n",
       "+=========+==========+\n",
       "| 1       | I        |\n",
       "+---------+----------+\n",
       "| 2       | II       |\n",
       "+---------+----------+\n",
       "| 3       | III      |\n",
       "+---------+----------+\n",
       "| 4       | IV       |\n",
       "+---------+----------+\n",
       "| 5       | V        |\n",
       "+---------+----------+\n",
       "Constants: None"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limits = [AtMost(1, \"calls\", 0.1), AtMost(5, \"calls\", 10)]\n",
    "runner = OpenAIChat(model_id=\"gpt-3.5-turbo-16k\", api_config=API_CONFIG, rate_limit=limits)\n",
    "\n",
    "Output(GenerateText(Template(\"Output as a latin numeral: {{input}}\"))).run(\n",
    "    runner, list(range(1,6))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
