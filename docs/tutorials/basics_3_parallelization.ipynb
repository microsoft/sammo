{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Load from parent directory if not installed\n",
    "import importlib\n",
    "import os\n",
    "\n",
    "if not importlib.util.find_spec(\"sammo\"):\n",
    "    import sys\n",
    "\n",
    "    sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Parallelization\n",
    "\n",
    "SAMMO automatically parallelizes runs across all **rows** of input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# %load -r 3:18 _init.py\n",
    "import pathlib\n",
    "import sammo\n",
    "from sammo.runners import OpenAIChat\n",
    "from sammo.base import Template, EvaluationScore\n",
    "from sammo.components import Output, GenerateText, ForEach, Union\n",
    "from sammo.extractors import ExtractRegex\n",
    "from sammo.data import DataTable\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "\n",
    "if not \"OPENAI_API_KEY\" in os.environ:\n",
    "    raise ValueError(\"Please set the environment variable 'OPENAI_API_KEY'.\")\n",
    "\n",
    "_ = sammo.setup_logger(\"WARNING\")  # we're only interested in warnings for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minibatches[#################################################################################]5/5[00:00<00:00, 333.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "+---------+----------+\n",
       "| input   | output   |\n",
       "+=========+==========+\n",
       "| 1       | I        |\n",
       "+---------+----------+\n",
       "| 2       | II       |\n",
       "+---------+----------+\n",
       "| 3       | III      |\n",
       "+---------+----------+\n",
       "| 4       | IV       |\n",
       "+---------+----------+\n",
       "| 5       | V        |\n",
       "+---------+----------+\n",
       "Constants: None"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner = OpenAIChat(\n",
    "    model_id=\"gpt-3.5-turbo\",\n",
    "    api_config={\"api_key\": os.environ[\"OPENAI_API_KEY\"]},\n",
    "    cache=os.getenv(\"CACHE_FILE\", \"cache.tsv\"),\n",
    ")\n",
    "numbers = list(range(1,6))\n",
    "spp = Output(GenerateText(Template(\"Output as a latin numeral: {{input}}\")))\n",
    "spp.run(runner, DataTable(numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Here, SAMMO automatically runs queries for the six inputs in parallel while adhering to query limits (by default, 2 queries per second). We can change this when constructing the runner. We can also skip constructing the `DataTable` and just pass the list directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minibatches[###################################################################################]5/5[00:00<??:??, 0.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "+---------+----------+\n",
       "| input   | output   |\n",
       "+=========+==========+\n",
       "| 1       | I        |\n",
       "+---------+----------+\n",
       "| 2       | II       |\n",
       "+---------+----------+\n",
       "| 3       | III      |\n",
       "+---------+----------+\n",
       "| 4       | IV       |\n",
       "+---------+----------+\n",
       "| 5       | V        |\n",
       "+---------+----------+\n",
       "Constants: None"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner = OpenAIChat(\n",
    "    model_id=\"gpt-3.5-turbo\",\n",
    "    api_config={\"api_key\": os.environ[\"OPENAI_API_KEY\"]},\n",
    "    cache=os.getenv(\"CACHE_FILE\", \"cache.tsv\"),\n",
    "    rate_limit=6\n",
    ")\n",
    "spp.run(runner, DataTable(numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "That's it! More complex throttling options are covered under special topics. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
